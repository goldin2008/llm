{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc260139-8ddb-454e-ade9-e88e4bfde842",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain openai weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47672cba-d00a-46d0-8441-5da41592c5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"<YOUR_OPENAI_API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3486b4e5-1444-4a5c-a255-1c8ba451082a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e218e60e-0983-482c-8d33-f1ccabcbc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/modules/state_of_the_union.txt\"\n",
    "res = requests.get(url)\n",
    "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
    "    f.write(res.text)\n",
    "\n",
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "960d296e-8d45-4f41-8c52-cb1136c33d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22d6487-85b2-45b0-bafc-959ed33960ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n",
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":61753},\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"address\":\"192.168.90.195:61754\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"address\":\"192.168.90.195:61753\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"action\":\"raft\",\"index\":0,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[]]\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"last_snapshot_index\":0,\"last_store_applied_index\":0,\"last_store_log_applied_index\":0,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":0,\"raft_last_index\":0,\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-08-15T00:11:15-04:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"raft no known peers, aborting election\",\"time\":\"2024-08-15T00:11:16-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.90.195:61753]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.90.195:61753\"],\"time\":\"2024-08-15T00:11:17-04:00\",\"voter\":true}\n",
      "{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"Embedded_at_8079\",\"Address\":\"192.168.90.195:61753\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-08-15T00:11:17-04:00\"}\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.90.195:61753\"],\"time\":\"2024-08-15T00:11:17-04:00\"}\n",
      "{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-08-15T00:11:17-04:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-08-15T00:11:17-04:00\"}\n",
      "{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-08-15T00:11:17-04:00\"}\n",
      "{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:9ea95b7f-3c81-43df-b5f1-f12d6298eb40 Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:amd64 UsedModules:[]}\",\"time\":\"2024-08-15T00:11:17-04:00\"}\n",
      "{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":2,\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":2,\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "{\"address\":\"192.168.90.195:61753\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"starting migration from old schema\",\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"legacy schema is empty, nothing to migrate\",\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"migration from the old schema has been successfully completed\",\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-08-15T00:11:18-04:00\"}\n",
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/leiyu/.local/share/weaviate/langchain_b4ba219984124447bf748b9fb826d55a/Q8XYC0E7rpw5/proplengths does not exist, creating new tracker\",\"time\":\"2024-08-15T00:11:19-04:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-08-15T00:11:19-04:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_b4ba219984124447bf748b9fb826d55a_Q8XYC0E7rpw5 in 3.999875ms\",\"time\":\"2024-08-15T00:11:19-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-08-15T00:11:19-04:00\",\"took\":286208}\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "\n",
    "client = weaviate.Client(\n",
    "  embedded_options = EmbeddedOptions()\n",
    ")\n",
    "\n",
    "vectorstore = Weaviate.from_documents(\n",
    "    client = client,    \n",
    "    documents = chunks,\n",
    "    embedding = OpenAIEmbeddings(),\n",
    "    by_text = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dafa5a34-1189-44a9-b202-17f10c18b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246fe2b6-8744-4c4c-b52c-38d9bda45a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. \\nUse the following pieces of retrieved context to answer the question. \\nIf you don't know the answer, just say that you don't know. \\nUse three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\\n\"))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "237c522d-65de-42f9-938f-28a3f96384ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "sys:1: ResourceWarning: unclosed socket <zmq.Socket(zmq.PUSH) at 0x12ddb5720>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/pydantic/main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't have the information about what the president said about Justice Breyer.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/leiyu/.local/share/weaviate/langchain_fe4220a0f5d64fe1910dad6abfefbbb8/4FF7Gbxzc4FR/proplengths does not exist, creating new tracker\",\"time\":\"2024-08-15T00:13:33-04:00\"}\n",
      "{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-08-15T00:13:33-04:00\",\"wait_for_cache_prefill\":false}\n",
      "{\"level\":\"info\",\"msg\":\"Created shard langchain_fe4220a0f5d64fe1910dad6abfefbbb8_4FF7Gbxzc4FR in 4.681958ms\",\"time\":\"2024-08-15T00:13:33-04:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-08-15T00:13:33-04:00\",\"took\":86834}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")\n",
    "\n",
    "query = \"What did the president say about Justice Breyer\"\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb1b17-cf7e-406e-8e70-a75a8feae8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
