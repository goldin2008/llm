{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53acfe81-22eb-49e9-9dbf-1b3d8e60a2d1",
   "metadata": {},
   "source": [
    "Earnings Call Transcripts contain actionable insights. Capture them, at scale.\n",
    "\n",
    "Analyst calls around earnings are scheduled quarterly for publicly listed companies, and similar conference calls cover activities including mergers and acquisitions, or CEO changes. Each disclosure may reveal information that materially impacts company strategy or stock valuation, but reviewing transcripts is time-consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71879cf7-bcc4-4493-b0af-8d9b3ffd8022",
   "metadata": {},
   "source": [
    "### jp\n",
    "\n",
    "1. Search of earnings transcripts, Single document Q&A. Multi document Semantic Search, Classification, Sentiment\n",
    "\n",
    "2. Empower international Private Bank(IPD) Advisors to summarize and extract relevant, timely, and accurate market insignts by training a LLM model with JPM Private Bank research. For example, \"where does JiM expect the S&P500 to get to within the next 30 days?\", or \"what does JPM think about the latest fed rate hike?\". This will allow them to make informed decisions, and to address client queries in a more timely manner, creating a first class experience for our clients. Integrate solution into Casey, existing WM bot.\n",
    "\n",
    "3. CPG Lending currently has a small number of researchers which are only capable of analysing a couple of companies in depth each week. Given the portfolio covers hundreds of businesses, there are many missed hedge opportunities. Currently, company or external research reports need to be reviewed and re-phrased to make a clear and concise recommendations which may lead to the execution of discretionary hedges. A LLM of the quality of GPT-4.0 or better could be used to prepare the barebones structure of a trade recommendation from public data sources(earning calls. investor presentations and annual/quarterly reports). GPT-4.0 could also be used to summarise earnings call transcriots, freeing up analvst time. Access to LLMIs would also allow the team to build more powertul relative value and early warning svstems, reducing the number of missed hedge opportunities.\n",
    "\n",
    "4. Summarize documents published on client websites such as fundsheets, annual reports, investor letters, board minute meetings, earnings presentations etc, with the capability to show only EDG specitic content (vs. generic summary) and make targeted actions from this (such as increase m/s with existing clients by new products, new pods etc. and find new clients who are tradine EDG products). e.g. of Board Meeting minutes - they have approval for new products and new hires. LLM should be able to read these and understand the opportunity this brings. E.g. board passes motion to manage and alternative risk premia investment program internally - therefore we should be pitching them our risk premia offering.\n",
    "\n",
    "5. Research LLM model with K: drive, user bucket access and internet connections to support writing of research reports. Some examples of use-cases that I thought might be helpful:\n",
    "- Q: \"Explain (for example } JPMorgan's Carbon Emissions goals and how the loan book is being used to nudge other companies to reduce their environmental impact using documents from K: drive folder\n",
    "- Q: Include citations!\n",
    "\n",
    "6. Leverage ChatGPT on the JPMorgan and industry competitors quarterly earnings and ad hoc financial conferences and investor days for key summaries, highlights, and sentiments, as well as direct quotes relating to specific themes.\n",
    "\n",
    "7. Summarize earnings, transcripts or news for competitor research \"- Extract info from news, 10-K, and analyst calls on key financial metrics and strategy\n",
    "- Identify trends, compare and contrast, and present information in easy to digest manner\"\n",
    "\n",
    "8. What: The LLM can be used to assist in generating quick competitor analysis/updates by summarizing key themes from earnings calls and conferences. The summary can then be fact-checked by human analysts.\n",
    "- Why: The CFA team spends significant time gathering information, analyzing and summarizing quarterly earnings call/conference transcripts from our competitors. (Time estimate: 100 hours per quarter)\n",
    "- When: Quarterly basis\n",
    "- How: The summaries capture key financial metrics, drivers, expected future performance/targets and macro conditions affecting the business. (Qualitiative info as well) Data Sources are public information taken from Intelligence Subscription Services such as Factset and S&P in text format.\n",
    "\n",
    "9. What: The LLM can help prepare answers beforehand for the purpose of answering equity research analyst questions which takes place at the end of an Earnings Release Presentations, conferences or Investor Day. Answers can be either quantitative or quantitative. The investor relations team will then vet these prepared answers before sharing these with the executives\n",
    "- Why: The Firmwide P&A team (along with Investor Relations and LOB P&A teams) spends significant time preparing for those questions(Time Estimate: 40 hours/quarter)\n",
    "- When: Ouarterly basis or Investor Day\n",
    "- How: Identify key opportunities and concerns on reported performance, performance targets, business drivers - predict questions from analysts and prepare answers for them.\n",
    "\n",
    "10. Generating summaries of lenethy financial documents (like earnings reports) is an important use-case for using LLMs at JPMC. Unfortunately, LLM generated summaries often have factually incorrect sentences due to the problem of hallucinations. One way to deal with such hallucinations is by using a second LLM to fact-check the summary. This can be done by prompting a fact-checker-LLM to do the following:\n",
    "- 1. extract a list of assertions from the generated summary\n",
    "- 2. mark each assertion as True/False\n",
    "- 3. rewrite the summary by only including the assertions that are marked True. While this results in a more accurate summary, it requires multiple calls to the fact-checker-LLM(currently GPT-4), which adds to the latency and cost of generating factually grounded summaries. Our goal is to investigate the use of open source models along with XAI techniques to reduce the cost of generating factually grounded summaries. Smaller open source models are faster to run and can be operated at lower cost compared to GPT-4. While their performance is lower than that of GPT-4. we believe that these models can be fine-tuned specifically for the task of refining summaries to be factually-grounded. Additionally, the white-box access to open-source models presents an opportunity to develop new XAI techniques that can enable better consistency checks for producing factually grounded summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc20bf3-0c1d-4a90-baa8-45deaf87bf63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c05096e-17de-432b-b503-5749cb03d83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae563ed-d84f-4dfb-87c9-91ef3b1b29e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
