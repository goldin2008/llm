{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eef089-3ac6-46d4-85ab-81232c699a8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd812dff-2fe9-43bc-91aa-2196c14f1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d58431b3-9715-4fbe-a9d6-40c4bb9d5d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876223a174444d58b0415c7ff5137ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494cb747df5b4f21b19b8cc81247ff30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e4cea32d1d4a7ab49eddebee8efbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7161bb622fc94ef4b686dfac29831938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7642f9f2a4fd4f35b89558a9da7ee753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1d82fc9e8241da85b762ca56de3139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e864e3ee6ca3409192229a1595910509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5693ed5d37db4048b6ea4f0885def2a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c8948479fe472bb5661a8cc9162343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9bfc17cf9d64d0c90ad5e3cda1c37e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiyu/opt/anaconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89ddf2fb99643b9b464c14376abfff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "docs = [\n",
    "    \"My first paragraph. That contains information\",\n",
    "    \"Python is a programming language.\",\n",
    "]\n",
    "document_embeddings = model.encode(docs)\n",
    "\n",
    "query = \"What is Python?\"\n",
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8370d5a-5fe9-4a17-b2e8-d1bd072fba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_embeddings[0]), len(document_embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b38461-335b-4094-9bb1-a3a3bcd598ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d9c09c-3a88-4cc2-9b8b-152efa8471ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df2bd27-f004-48b3-82dc-a51697c5174b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03353ed5ffe24ac595822d1609b643bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/607 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0002d2caa7422ab667e0c2aa6f95da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cd0ca36e404f488d67c4fd8fc5323a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/148 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dc7d44e4b8445e9558aa41e2957ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e98b8c750df4268936b9c40289d163d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae2403d04614c629b3446322fb7865f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  A man is eating pasta.\n",
      "0.67\tA man is eating food.\n",
      "0.34\tA man is eating a piece of bread.\n",
      "0.08\tA man is riding a horse.\n",
      "0.07\tA man is riding a white horse on an enclosed ground.\n",
      "0.01\tThe girl is carrying a baby.\n",
      "0.01\tTwo men pushed carts through the woods.\n",
      "0.01\tA monkey is playing drums.\n",
      "0.01\tA woman is playing violin.\n",
      "0.01\tA cheetah is running behind its prey.\n",
      "Scores: [0.67323726 0.34102538 0.00542465 0.07569346 0.00525379 0.00536814\n",
      " 0.06676243 0.00534826 0.00516718]\n",
      "Indices: [0 1 3 6 2 5 7 4 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nScores: [0.6732372, 0.34102544, 0.00542465, 0.07569341, 0.00525378, 0.00536814, 0.06676237, 0.00534825, 0.00516717]\\nIndices: [0 1 3 6 2 5 7 4 8]\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "# 1. Load a pretrained CrossEncoder model\n",
    "model = CrossEncoder(\"cross-encoder/stsb-distilroberta-base\")\n",
    "\n",
    "# We want to compute the similarity between the query sentence...\n",
    "query = \"A man is eating pasta.\"\n",
    "\n",
    "# ... and all sentences in the corpus\n",
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]\n",
    "\n",
    "# 2. We rank all sentences in the corpus for the query\n",
    "ranks = model.rank(query, corpus)\n",
    "\n",
    "# Print the scores\n",
    "print(\"Query: \", query)\n",
    "for rank in ranks:\n",
    "    print(f\"{rank['score']:.2f}\\t{corpus[rank['corpus_id']]}\")\n",
    "\"\"\"\n",
    "Query:  A man is eating pasta.\n",
    "0.67    A man is eating food.\n",
    "0.34    A man is eating a piece of bread.\n",
    "0.08    A man is riding a horse.\n",
    "0.07    A man is riding a white horse on an enclosed ground.\n",
    "0.01    The girl is carrying a baby.\n",
    "0.01    Two men pushed carts through the woods.\n",
    "0.01    A monkey is playing drums.\n",
    "0.01    A woman is playing violin.\n",
    "0.01    A cheetah is running behind its prey.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Alternatively, you can also manually compute the score between two sentences\n",
    "import numpy as np\n",
    "\n",
    "sentence_combinations = [[query, sentence] for sentence in corpus]\n",
    "scores = model.predict(sentence_combinations)\n",
    "\n",
    "# Sort the scores in decreasing order to get the corpus indices\n",
    "ranked_indices = np.argsort(scores)[::-1]\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Indices:\", ranked_indices)\n",
    "\"\"\"\n",
    "Scores: [0.6732372, 0.34102544, 0.00542465, 0.07569341, 0.00525378, 0.00536814, 0.06676237, 0.00534825, 0.00516717]\n",
    "Indices: [0 1 3 6 2 5 7 4 8]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4769409e-fb57-45eb-84fa-f19979894c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
