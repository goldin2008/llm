{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213962c9-ad00-4583-a172-84e2f2472d15",
   "metadata": {},
   "source": [
    "### Supervised Fine-Tuning (SFT)\n",
    "\n",
    "Creating our own instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac598fa-02e3-416a-b966-813a7b61c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai==1.37.1\n",
    "datasets==2.20.0\n",
    "tqdm==4.66.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eca3ff-84cf-4da6-8fc0-54766445b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Tuple\n",
    "from datasets import Dataset\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce77ed4-d3f5-4923-bb77-be1b432c0550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles_from_json(file_path: str) -> Dataset:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"id\": [item[\"id\"] for item in data[\"artifact_data\"]],\n",
    "            \"content\": [item[\"content\"] for item in data[\"artifact_data\"]],\n",
    "            \"platform\": [item[\"platform\"] for item in data[\"artifact_data\"]],\n",
    "            \"author_id\": [item[\"author_id\"] for item in data[\"artifact_data\"]],\n",
    "            \"author_full_name\": [item[\"author_full_name\"] for item in data[\"artifact_data\"]],\n",
    "            \"link\": [item[\"link\"] for item in data[\"artifact_data\"]],\n",
    "        }\n",
    "    )\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^\\w\\s.,!?']\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_substrings(dataset: Dataset, min_length: int = 1000, max_length: int = 2000) -> List[str]:\n",
    "    extracts = []\n",
    "    sentence_pattern = r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s\"\n",
    "    for article in dataset[\"content\"]:\n",
    "        cleaned_article = clean_text(article)\n",
    "        sentences = re.split(sentence_pattern, cleaned_article)\n",
    "        current_chunk = \"\"\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "            if len(current_chunk) + len(sentence) <= max_length:\n",
    "                current_chunk += sentence + \" \"\n",
    "            else:\n",
    "                if len(current_chunk) >= min_length:\n",
    "                    extracts.append(current_chunk.strip())\n",
    "                current_chunk = sentence + \" \"\n",
    "        if len(current_chunk) >= min_length:\n",
    "            extracts.append(current_chunk.strip())\n",
    "    return extracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5775adf-1a61-4723-8f62-3bd7940159e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionAnswerSet:\n",
    "    def __init__(self, pairs: List[Tuple[str, str]]):\n",
    "        self.pairs = pairs\n",
    "    @classmethod\n",
    "    def from_json(cls, json_str: str) -> 'InstructionAnswerSet':\n",
    "        data = json.loads(json_str)\n",
    "        pairs = [(pair['instruction'], pair['answer'])\n",
    "                 for pair in data['instruction_answer_pairs']]\n",
    "        return cls(pairs)\n",
    "    def __iter__(self):\n",
    "        return iter(self.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6539b-4809-4e1e-8e54-1b1dca5b0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction_answer_pairs(\n",
    "    extract: str, client: OpenAI\n",
    ") -> List[Tuple[str, str]]:\n",
    "    prompt = f\"\"\"Based on the following extract, generate five instruction-answer pairs. Each instruction \\\n",
    "must ask to write about a specific topic contained in the context. each answer \\\n",
    "must provide a relevant paragraph based on the information found in the \\\n",
    "context. Only use concepts from the context to generate the instructions. \\\n",
    "Instructions must never explicitly mention a context, a system, a course, or an extract. \\\n",
    "Instructions must be self-contained and general. \\\n",
    "Answers must imitate the writing style of the context. \\\n",
    "Example instruction: Explain the concept of an LLM Twin. \\\n",
    "Example answer: An LLM Twin is essentially an AI character that mimics your writing style, personality, and voice. \\\n",
    "It's designed to write just like you by incorporating these elements into a language model. \\\n",
    "The idea is to create a digital replica of your writing habits using advanced AI techniques. \\\n",
    "Provide your response in JSON format with the following structure:\n",
    "{{\n",
    "    \"instruction_answer_pairs\": [\n",
    "        {{\"instruction\": \"...\", \"answer\": \"...\"}},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "Extract:\n",
    "{extract}\n",
    "\"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \"content\": \"You are a helpful assistant who \\\n",
    "            generates instruction-answer pairs based on the given context. \\\n",
    "            Provide your response in JSON format.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        max_tokens=1200,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    # Parse the structured output\n",
    "    result = InstructionAnswerSet.from_json(completion.choices[0].message.content)\n",
    "    # Convert to list of tuples\n",
    "    return result.pairs\n",
    "\n",
    "def create_instruction_dataset(\n",
    "    dataset: Dataset, client: OpenAI, num_workers: int = 4\n",
    ") -> Dataset:\n",
    "    extracts = extract_substrings(dataset)\n",
    "    instruction_answer_pairs = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(generate_instruction_answer_pairs, extract, client)\n",
    "            for extract in extracts\n",
    "        ]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)\n",
    "        ):\n",
    "            instruction_answer_pairs.extend(future.result())\n",
    "    instructions, answers = zip(*instruction_answer_pairs)\n",
    "    return Dataset.from_dict(\n",
    "        {\"instruction\": list(instructions), \"output\": list(answers)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1861b4-cbdc-4d33-8807-8afa5b8c08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_id: str) -> Dataset:\n",
    "    client = OpenAI()\n",
    "    # 1. Load the raw data\n",
    "    raw_dataset = load_articles_from_json(\"cleaned_documents.json\")\n",
    "    print(\"Raw dataset:\")\n",
    "    print(raw_dataset.to_pandas())\n",
    "    # 2. Create instructiondataset\n",
    "    instruction_dataset = create_instruction_dataset(raw_dataset, client)\n",
    "    print(\"Instruction dataset:\")\n",
    "    print(instruction_dataset.to_pandas())\n",
    "    # 3. Train/test split and export\n",
    "    filtered_dataset = instruction_dataset.train_test_split(test_size=0.1)\n",
    "    filtered_dataset.push_to_hub(\"mlabonne/llmtwin\")\n",
    "    return filtered_dataset\n",
    "Dataset({\n",
    "    features: ['instruction', 'output'],\n",
    "    num_rows: 3335\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dab6e9-bd5f-4e3e-9057-40baf7aa89d8",
   "metadata": {},
   "source": [
    "#### Fine-tuning in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1009d55-329a-42c8-83ce-1d3d73c0c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = YOUR_API_KEY\n",
    "COMET_API_KEY = YOUR_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e4fe0-4745-4fbf-b992-80dbc570e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import TrainingArguments, TextStreamerfrom unsloth import FastLanguageModel, is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf459d-119a-4d7a-b9d6-61c1d9dfa9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"meta-llama/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=False,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e82915-b045-472a-abbe-986d6d896942",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = load_dataset(\"mlabonne/llmtwin\")\n",
    "dataset2 = load_dataset(\"mlabonne/FineTome-Alpaca-100k\", split=\"train[:10000]\")\n",
    "dataset = concatenate_datasets([dataset1, dataset2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de9193-f50c-4ea9-bd42-27e56c0608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{}\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "dataset = dataset.map(format_samples, batched=True, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501896f4-8d74-4aa5-87ed-b1f8ed16a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32250753-187b-4500-9242-b65482cef11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args=TrainingArguments(\n",
    "    learning_rate=3e-4,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    logging_steps=1,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=10,\n",
    "    output_dir=\"output\",\n",
    "    report_to=\"comet_ml\",\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    packing=True,\n",
    "    args=training_args\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b58a52-e364-4ba8-bda2-4259d58e2db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "message = alpaca_prompt.format(\"Write a paragraph to introduce supervised fine-tuning.\", \"\")\n",
    "inputs = tokenizer([message], return_tensors=\"pt\").to(\"cuda\")\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=256, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc105eb-de59-439f-a6f5-34ab8cfce527",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_merged(\"model\", tokenizer, save_method=\"merged_16bit\")\n",
    "model.push_to_hub_merged(\"mlabonne/TwinLlama-3.1-8B\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e7884-01f7-4a91-8a91-b311d08cf41f",
   "metadata": {},
   "source": [
    "### Fine-Tuning with Preference Alignment\n",
    "`Reinforcement Learning from Human Feedback (RLHF)` combines reinforcement learning (RL) with human input to align models with human preferences and values.\n",
    "\n",
    "**Reinforcement Learning (RL)** is one type of machine learning where agents take actions in an environment aimed at maximizing their cumulative rewards. The agent's behavior is defined by the **policy**. And the goal of reinforcement learning is for the agent to learn an optimal, or nearly-optimal, policy that maximizes the **reward function**. \n",
    "the original policy is based on the instruct PEFT model - this is the LLM before detoxification. Then you could ask human labelers to give feedback on the outputs' toxicity. However, it can be expensive to use them for the entire fine-tuning process. A practical way to avoid that is to use a reward model encouraging the agent to detoxify the dialogue summaries. The intuitive approach would be to do some form of sentiment analysis across two classes (`nothate` and `hate`) and give a higher reward if there is higher a chance of getting class `nothate` as an output. \n",
    "\n",
    "For example, we can mention that having human labelers for the entire finetuning process can be expensive. A practical way to avoid that is to use a reward model.\n",
    "\n",
    "use feedback generated by a model\n",
    "\n",
    "You will use [Meta AI's RoBERTa-based hate speech model](https://huggingface.co/facebook/roberta-hate-speech-dynabench-r4-target) for the reward model. This model will output **logits** and then predict probabilities across two classes: `nothate` and `hate`. The logits of the output `nothate` will be taken as a positive reward. Then, the model will be fine-tuned with PPO using those reward values.\n",
    "\n",
    "Creating our own preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031126f7-d347-4b93-b04a-33df7c887308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "from datasets import Dataset\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7237c5f-4872-4382-a782-b60a44b19e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreferenceSet:\n",
    "    def __init__(self, triples: List[Tuple[str, str, str]]):\n",
    "        self.triples = triples\n",
    "    @classmethod\n",
    "    def from_json(cls, json_str: str) -> 'PreferenceSet':\n",
    "        data = json.loads(json_str)\n",
    "        triples = [(triple['instruction'], triple['generated_answer'], triple['extracted_answer'])\n",
    "                   for triple in data['preference_triples']]\n",
    "        return cls(triples)\n",
    "    def __iter__(self):\n",
    "        return iter(self.triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b778160-0206-4207-bb9a-d588a5010cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles_from_json(file_path: str) -> Dataset:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"id\": [item[\"id\"] for item in data[\"artifact_data\"]],\n",
    "            \"content\": [item[\"content\"] for item in data[\"artifact_data\"]],\n",
    "            \"platform\": [item[\"platform\"] for item in data[\"artifact_data\"]],\n",
    "            \"author_id\": [item[\"author_id\"] for item in data[\"artifact_data\"]],\n",
    "            \"author_full_name\": [item[\"author_full_name\"] for item in data[\"artifact_data\"]],\n",
    "            \"link\": [item[\"link\"] for item in data[\"artifact_data\"]],\n",
    "        }\n",
    "    )\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"[^\\w\\s.,!?']\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_substrings(dataset: Dataset, min_length: int = 1000, max_length: int = 2000) -> List[str]:\n",
    "    extracts = []\n",
    "    sentence_pattern = r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s\"\n",
    "    for article in dataset[\"content\"]:\n",
    "        cleaned_article = clean_text(article)\n",
    "        sentences = re.split(sentence_pattern, cleaned_article)\n",
    "        current_chunk = \"\"\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "            if len(current_chunk) + len(sentence) <= max_length:\n",
    "                current_chunk += sentence + \" \"\n",
    "            else:\n",
    "                if len(current_chunk) >= min_length:\n",
    "                    extracts.append(current_chunk.strip())\n",
    "                current_chunk = sentence + \" \"\n",
    "        if len(current_chunk) >= min_length:\n",
    "            extracts.append(current_chunk.strip())\n",
    "    return extracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99485c-9447-49d2-9986-40c85be55666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_preference_triples(extract: str, client: OpenAI) -> List[Tuple[str, str, str]]:\n",
    "    prompt = f\"\"\"Based on the following extract, generate five instruction-answer triples. Each triple should consist of:\n",
    "1. An instruction asking about a specific topic in the context.\n",
    "2. A generated answer that attempts to answer the instruction based on the context.\n",
    "3. An extracted answer that is a relevant excerpt directly from the given context.\n",
    "Instructions must be self-contained and general, without explicitly mentioning a context, system, course, or extract.\n",
    "Important:\n",
    "- Ensure that the extracted answer is a verbatim copy from the context, including all punctuation and apostrophes.\n",
    "- Do not add any ellipsis (...) or [...]  to indicate skipped text in the extracted answer.\n",
    "- If the relevant text is not continuous, use two separate sentences from the context instead of skipping text.\n",
    "Provide your response in JSON format with the following structure:\n",
    "{{\n",
    "    \"preference_triples\": [\n",
    "        {{\n",
    "            \"instruction\": \"...\",\n",
    "            \"generated_answer\": \"...\",\n",
    "            \"extracted_answer\": \"...\"\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "    Extract:\n",
    "    {extract}\n",
    "\"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who generates instruction-answer triples based on the given context. Each triple should include an instruction, a generated answer, and an extracted answer from the context. Provide your response in JSON format.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    result = PreferenceSet.from_json(completion.choices[0].message.content)\n",
    "    return result.triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e6da2-bd8d-4026-8fb6-7a2421035fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short_answers(dataset: Dataset, min_length: int = 100) -> Dataset:\n",
    "    def is_long_enough(example):\n",
    "        return len(example['chosen']) >= min_length\n",
    "    return dataset.filter(is_long_enough)\n",
    "\n",
    "def filter_answer_format(dataset: Dataset) -> Dataset:\n",
    "    def is_valid_format(example):\n",
    "        chosen = example['chosen']\n",
    "        return (len(chosen) > 0 and\n",
    "                chosen[0].isupper() and\n",
    "                chosen[-1] in ('.', '!', '?'))\n",
    "    return dataset.filter(is_valid_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0d747-1e70-4a1a-8466-edead0b143e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preference_dataset(dataset: Dataset, client: OpenAI, num_workers: int = 4) -> Dataset:\n",
    "    extracts = extract_substrings(dataset)\n",
    "    preference_triples = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(generate_preference_triples, extract, client)\n",
    "            for extract in extracts\n",
    "        ]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "            preference_triples.extend(future.result())\n",
    "    instructions, generated_answers, extracted_answers = zip(*preference_triples)\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"prompt\": list(instructions),\n",
    "            \"rejected\": list(generated_answers),\n",
    "            \"chosen\": list(extracted_answers)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a35000-9e46-4fd5-a4ab-504475c79dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_id: str) -> Dataset:\n",
    "    client = OpenAI()\n",
    "    # 1. Load the raw data\n",
    "    raw_dataset = load_articles_from_json(\"cleaned_documents.json\")\n",
    "    print(\"Raw dataset:\")\n",
    "    print(raw_dataset.to_pandas())\n",
    "    # 2. Create preference dataset\n",
    "    dataset = create_preference_dataset(raw_dataset, client)\n",
    "    print(\"Preference dataset:\")\n",
    "    print(dataset.to_pandas())\n",
    "    # 3. Filter out samples with short answers\n",
    "    dataset = filter_short_answers(dataset)\n",
    "    # 4. Filter answers based on format\n",
    "    dataset = filter_answer_format(dataset)\n",
    "    # 5. Export\n",
    "    dataset.push_to_hub(dataset_id)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb26abf-2906-4b08-8c23-fcf2b744ba5a",
   "metadata": {},
   "source": [
    "#### Implementing DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36451b-abbb-4eae-afce-4be4a35a7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments, TextStreamer\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supportedfrom trl import DPOConfig, DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af369d5b-a897-4ef2-a039-84430f5fb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = YOUR_API_KEY\n",
    "COMET_API_KEY = YOUR_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa437203-8223-48e8-9d0c-441b711564a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import PatchDPOTrainer\n",
    "PatchDPOTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc957a8-67f8-4c53-8601-c850935a8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 2048\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"mlabonne/TwinLlama-3.1-8B\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=False,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89680ac-dbfd-4f5e-b2ba-359e6792385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"mlabonne/llmtwin-dpo\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3148723-3211-446d-b56e-4ef4a33e7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{}\n",
    "### Response:\n",
    "\"\"\"\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def format_samples(example):\n",
    "    example[\"prompt\"] = alpaca_template.format(example[\"prompt\"])\n",
    "    example[\"chosen\"] = example['chosen'] + EOS_TOKEN\n",
    "    example[\"rejected\"] = example['rejected'] + EOS_TOKEN\n",
    "    return {\"prompt\": example[\"prompt\"], \"chosen\": example[\"chosen\"], \"rejected\": example[\"rejected\"]}\n",
    "dataset = dataset.map(format_samples)\n",
    "dataset = dataset.train_test_split(test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e5b919-67be-45bf-be6c-58e9ba1c0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config=DPOConfig(\n",
    "    learning_rate=2e-6,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    fp16=not is_bfloat16_supported(),\n",
    "    bf16=is_bfloat16_supported(),\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=10,\n",
    "    output_dir=\"output\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    logging_steps=1,\n",
    "    report_to=\"comet_ml\",\n",
    "    seed=0,\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    tokenizer=tokenizer,\n",
    "    beta=0.5,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    max_length=max_seq_length//2,\n",
    "    max_prompt_length=max_seq_length//2,\n",
    "    args=config\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275b877-6c7f-4ac0-bd71-295c39ae726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "message = alpaca_template.format(\"Write a paragraph to introduce supervised fine-tuning.\", \"\")\n",
    "inputs = tokenizer([message], return_tensors=\"pt\").to(\"cuda\")\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=256, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56536d2c-79a6-4c2a-ad03-824c9e441c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained_merged(\"model\", tokenizer, save_method=\"merged_16bit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
