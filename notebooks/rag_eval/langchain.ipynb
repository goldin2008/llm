{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586226e7",
   "metadata": {},
   "source": [
    "# Langchain\n",
    "## Evaluating Langchain QA Chains\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models. It can also be used to create RAG systems (or QA systems as they are reffered to in langchain). If you want to know more about creating RAG systems with langchain you can check the [docs](https://python.langchain.com/docs/use_cases/question_answering/).\n",
    "\n",
    "With this integration you can easily evaluate your QA chains with the metrics offered in ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fe0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ragas langchain_openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9276955-9954-44d4-a79e-8e4ae9e32180",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ragas==0.1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5deb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attach to the existing event loop when using jupyter notebooks\n",
    "import nest_asyncio\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# IMPORTANT: Remember to create a .env variable containing: OPENAI_API_KEY=sk-xyz where xyz is your key\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize the OpenAI API client\n",
    "openai.api_key = api_key\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e32dc",
   "metadata": {},
   "source": [
    "First lets load the dataset. We are going to build a generic QA system over the [NYC wikipedia page](https://en.wikipedia.org/wiki/New_York_City). Load the dataset and create the `VectorstoreIndex` and the `RetrievalQA` from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa9a986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain/indexes/vectorstore.py:127: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders.hugging_face_dataset import (\n",
    "    HuggingFaceDatasetLoader,\n",
    ")\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "loader = TextLoader(\"./nyc_wikipedia/nyc_text.txt\")\n",
    "\n",
    "# pass the embedding as parameter, in the example is empty\n",
    "index = VectorstoreIndexCreator(embedding=embeddings).from_loaders([loader])\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=index.vectorstore.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ebdf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leiyu/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'New York City was named in honor of the Duke of York, who later became King James II of England. The city was renamed New York after King Charles II of England granted the lands to his brother, the Duke of York, when England seized the territory from Dutch control in 1664.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing it out\n",
    "\n",
    "question = \"How did New York City get its name?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748787c1",
   "metadata": {},
   "source": [
    "Now in order to evaluate the qa system we generated a few relevant questions. We've generated a few question for you but feel free to add any you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67ce0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = [\n",
    "    \"What is the population of New York City as of 2020?\",\n",
    "    \"Which borough of New York City has the highest population?\",\n",
    "    \"What is the economic significance of New York City?\",\n",
    "    \"How did New York City get its name?\",\n",
    "    \"What is the significance of the Statue of Liberty in New York City?\",\n",
    "]\n",
    "\n",
    "eval_answers = [\n",
    "    \"8,804,190\",\n",
    "    \"Brooklyn\",\n",
    "    \"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\",\n",
    "    \"New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.\",\n",
    "    \"The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.\",\n",
    "]\n",
    "\n",
    "examples = [\n",
    "    {\"query\": q, \"ground_truth\": [eval_answers[i]]}\n",
    "    for i, q in enumerate(eval_questions)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b7e2c4",
   "metadata": {},
   "source": [
    "## Introducing `RagasEvaluatorChain`\n",
    "\n",
    "`RagasEvaluatorChain` creates a wrapper around the metrics ragas provides (documented [here](https://github.com/explodinggradients/ragas/blob/main/docs/concepts/metrics/index.md)), making it easier to run these evaluation with langchain and langsmith.\n",
    "\n",
    "The evaluator chain has the following APIs\n",
    "\n",
    "- `__call__()`: call the `RagasEvaluatorChain` directly on the result of a QA chain.\n",
    "- `evaluate()`: evaluate on a list of examples (with the input queries) and predictions (outputs from the QA chain). \n",
    "- `evaluate_run()`: method implemented that is called by langsmith evaluators to evaluate langsmith datasets.\n",
    "\n",
    "lets see each of them in action to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f89d719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Manhattan has the highest population density among the boroughs of New York City.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain({\"query\": eval_questions[1]})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81fa9c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Statue of Liberty in New York City is a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants as they arrived in the late 19th and early 20th centuries, representing freedom and cultural diversity. Today, it continues to be an iconic symbol of freedom and a welcoming beacon for visitors to the city.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain(examples[4])\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd308e1b-ea49-4957-b91e-90b2c7fab04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.14\n"
     ]
    }
   ],
   "source": [
    "import ragas\n",
    "\n",
    "print(ragas.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d9266d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ragas.langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevalchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RagasEvaluatorChain\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     faithfulness,\n\u001b[1;32m      5\u001b[0m     answer_relevancy,\n\u001b[1;32m      6\u001b[0m     context_precision,\n\u001b[1;32m      7\u001b[0m     context_recall,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# create evaluation chains\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ragas.langchain'"
     ]
    }
   ],
   "source": [
    "from ragas.langchain.evalchain import RagasEvaluatorChain\n",
    "\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "\n",
    "# create evaluation chains\n",
    "faithfulness_chain = RagasEvaluatorChain(metric=faithfulness)\n",
    "answer_rel_chain = RagasEvaluatorChain(metric=answer_relevancy)\n",
    "context_rel_chain = RagasEvaluatorChain(metric=context_precision)\n",
    "context_recall_chain = RagasEvaluatorChain(metric=context_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb95467",
   "metadata": {},
   "source": [
    "1. `__call__()`\n",
    "\n",
    "Directly run the evaluation chain with the results from the QA chain. Do note that metrics like context_precision and faithfulness require the `source_documents` to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b574584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the significance of the Statue of Liberty in New York City?',\n",
       " 'ground_truth': ['The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.'],\n",
       " 'result': 'The Statue of Liberty in New York City is a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants as they arrived in the U.S. in the late 19th and early 20th centuries. Today, it continues to represent freedom and cultural diversity, making it an iconic landmark in the city.',\n",
       " 'source_documents': [Document(id='5ce91250-ddeb-4bc5-a5ad-abfb97960012', metadata={'source': './nyc_wikipedia/nyc_text.txt'}, page_content='from 1785 until 1790, and has been the largest U.S. city since 1790. The Statue of Liberty greeted millions of immigrants as they came to the U.S. by ship in the late 19th and early 20th centuries, and is a symbol of the U.S. and its ideals of liberty and peace. In the 21st century, New York City has emerged as a global node of creativity, entrepreneurship, and as a symbol of freedom and cultural diversity. The New York Times has won the most Pulitzer Prizes for journalism and remains the U.S. media\\'s \"newspaper of record\". In 2019, New York City was voted the greatest city in the world in a survey of over 30,000 people from 48 cities worldwide, citing its cultural diversity.Many districts and monuments in New York City are major landmarks, including three of the world\\'s ten most visited tourist attractions in 2013. A record 66.6 million tourists visited New York City in 2019. Times Square is the brightly illuminated hub of the Broadway Theater District, one of the world\\'s busiest'),\n",
       "  Document(id='9f339ab1-8532-4c93-a823-c4b3c1f3dcbb', metadata={'source': './nyc_wikipedia/nyc_text.txt'}, page_content=\"The Statue of Liberty National Monument and Ellis Island Immigration Museum are managed by the National Park Service and are in both New York and New Jersey. They are joined in the harbor by Governors Island National Monument. Historic sites under federal management on Manhattan Island include Stonewall National Monument; Castle Clinton National Monument; Federal Hall National Memorial; Theodore Roosevelt Birthplace National Historic Site; General Grant National Memorial (Grant's Tomb); African Burial Ground National Monument; and Hamilton Grange National Memorial. Hundreds of properties are listed on the National Register of Historic Places or as a National Historic Landmark.\"),\n",
       "  Document(id='a6e6f42b-bded-4b15-8420-66e4a9471b31', metadata={'source': './nyc_wikipedia/nyc_text.txt'}, page_content=\"The majority of the most high-profile tourist destinations to the city are situated in Manhattan. These include Times Square; Broadway theater productions; the Empire State Building; the Statue of Liberty; Ellis Island; the United Nations headquarters; the World Trade Center (including the National September 11 Memorial & Museum and One World Trade Center); the art museums along Museum Mile; green spaces such as Central Park, Washington Square Park, the High Line, and the medieval gardens of The Cloisters; the Stonewall Inn; Rockefeller Center; ethnic enclaves including the Manhattan Chinatown, Koreatown, Curry Hill, Harlem, Spanish Harlem, Little Italy, and Little Australia; luxury shopping along Fifth and Madison Avenues; and events such as the Halloween Parade in Greenwich Village; the Brooklyn Bridge (shared with Brooklyn); the Macy's Thanksgiving Day Parade; the lighting of the Rockefeller Center Christmas Tree; the St. Patrick's Day Parade; seasonal activities such as ice\"),\n",
       "  Document(id='b653e4fd-81a1-412d-94af-41d49b85c1da', metadata={'source': './nyc_wikipedia/nyc_text.txt'}, page_content=\"the nation. Anchored by Wall Street in the Financial District of Lower Manhattan, New York City has been called both the world's leading financial and fintech center and the most economically powerful city in the world, and is home to the world's two largest stock exchanges by total market capitalization, the New York Stock Exchange and Nasdaq.The Stonewall Inn in Greenwich Village, part of the Stonewall National Monument, is considered the historic epicenter of LGBTQ+ culture and the birthplace of the modern gay rights movement. New York City is the headquarters of the global art market, with numerous art galleries and auction houses collectively hosting half of the world’s art auctions, and the Metropolitan Museum of Art is both the largest art museum and the most visited museum in the United States. Governors Island in New York Harbor is planned to host a US$1 billion research and education center as a leader the climate crisis.\")]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck the result that we are going to validate.\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d182f",
   "metadata": {},
   "source": [
    "**Faithfulness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ede32cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = faithfulness_chain(result)\n",
    "eval_result[\"faithfulness_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a080160",
   "metadata": {},
   "source": [
    "High faithfulness_score means that there are exact consistency between the source documents and the answer.\n",
    "\n",
    "You can check lower faithfulness scores by changing the result (answer from LLM) or source_documents to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d46535f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_result = result.copy()\n",
    "fake_result[\"result\"] = \"we are the champions\"\n",
    "eval_result = faithfulness_chain(fake_result)\n",
    "eval_result[\"faithfulness_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a66f8",
   "metadata": {},
   "source": [
    "**Context Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94b5544e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing some input keys: {'ground_truths'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mcontext_recall_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m eval_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_recall_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:170\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     emit_warning()\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain/chains/base.py:381\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    379\u001b[0m }\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain/chains/base.py:164\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    163\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    165\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain/chains/base.py:152\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    146\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m     inputs,\n\u001b[1;32m    148\u001b[0m     run_id,\n\u001b[1;32m    149\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    150\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    160\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    161\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/langchain/chains/base.py:282\u001b[0m, in \u001b[0;36mChain._validate_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    280\u001b[0m missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys)\u001b[38;5;241m.\u001b[39mdifference(inputs)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_keys:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing some input keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Missing some input keys: {'ground_truths'}"
     ]
    }
   ],
   "source": [
    "eval_result = context_recall_chain(result)\n",
    "eval_result[\"context_recall_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d624d4",
   "metadata": {},
   "source": [
    "High context_recall_score means that the ground truth is present in the source documents.\n",
    "\n",
    "You can check lower context recall scores by changing the source_documents to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc25156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "fake_result = result.copy()\n",
    "fake_result[\"source_documents\"] = [Document(page_content=\"I love christmas\")]\n",
    "eval_result = context_recall_chain(fake_result)\n",
    "eval_result[\"context_recall_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11295b5",
   "metadata": {},
   "source": [
    "2. `evaluate()`\n",
    "\n",
    "Evaluate a list of inputs/queries and the outputs/predictions from the QA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce7bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the queries as a batch for efficiency\n",
    "predictions = qa_chain.batch(examples)\n",
    "\n",
    "# evaluate\n",
    "print(\"evaluating...\")\n",
    "r = faithfulness_chain.evaluate(examples, predictions)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55299f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate context recall\n",
    "print(\"evaluating...\")\n",
    "r = context_recall_chain.evaluate(examples, predictions)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc71587",
   "metadata": {},
   "source": [
    "## Evaluate with langsmith\n",
    "\n",
    "[Langsmith](https://docs.smith.langchain.com/) is a platform that helps to debug, test, evaluate and monitor chains and agents built on any LLM framework. It also seamlessly integrates with LangChain. \n",
    "\n",
    "Langsmith also has a tools to build a testing dataset and run evaluations against them and with `RagasEvaluatorChain` you can use the ragas metrics for running langsmith evaluations as well. To know more about langsmith evaluations checkout the [quickstart](https://docs.smith.langchain.com/evaluation/quickstart).\n",
    "\n",
    "\n",
    "Lets start of creating the dataset with the NYC questions listed in `eval_questions`. Create a new langsmith dataset and upload the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75144c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset creation\n",
    "\n",
    "from langsmith import Client\n",
    "from langsmith.utils import LangSmithError\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"NYC test\"\n",
    "\n",
    "try:\n",
    "    # check if dataset exists\n",
    "    dataset = client.read_dataset(dataset_name=dataset_name)\n",
    "    print(\"using existing dataset: \", dataset.name)\n",
    "except LangSmithError:\n",
    "    # if not create a new one with the generated query examples\n",
    "    dataset = client.create_dataset(\n",
    "        dataset_name=dataset_name, description=\"NYC test dataset\"\n",
    "    )\n",
    "    for e in examples:\n",
    "        client.create_example(\n",
    "            inputs={\"query\": e[\"query\"]},\n",
    "            outputs={\"ground_truth\": e[\"ground_truth\"]},\n",
    "            dataset_id=dataset.id,\n",
    "        )\n",
    "\n",
    "    print(\"Created a new dataset: \", dataset.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0181dac",
   "metadata": {},
   "source": [
    "![](../../_static/langsmith-dataset.png)\n",
    "\n",
    "As you can see the questions have been uploaded. Now you can run your QA chain against this test dataset and compare the results in the langchain platform. \n",
    "\n",
    "Before you call `run_on_dataset` you need a factory function which creates a new instance of the QA chain you want to test. This is so that the internal state is not reused when running against each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6decc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# factory function that return a new qa chain\n",
    "def create_qa_chain(return_context=True):\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=index.vectorstore.as_retriever(),\n",
    "        return_source_documents=return_context,\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ddc97",
   "metadata": {},
   "source": [
    "Now lets run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.smith import RunEvalConfig, run_on_dataset\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    custom_evaluators=[\n",
    "        faithfulness_chain,\n",
    "        answer_rel_chain,\n",
    "        context_rel_chain,\n",
    "        context_recall_chain,\n",
    "    ],\n",
    "    prediction_key=\"result\",\n",
    ")\n",
    "\n",
    "result = run_on_dataset(\n",
    "    client,\n",
    "    dataset_name,\n",
    "    create_qa_chain,\n",
    "    evaluation=evaluation_config,\n",
    "    input_mapper=lambda x: x,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64bb0c4",
   "metadata": {},
   "source": [
    "You can follow the link to open the result for the run in langsmith. Check out the scores for each example too\n",
    "\n",
    "![](../../_static/langsmith-evaluation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125857c9",
   "metadata": {},
   "source": [
    "Now if you want to dive more into the reasons for the scores and how to improve them, click on any example and open the feedback tab. This will show you each scores.\n",
    "\n",
    "![](../../_static/langsmith-feedback.png)\n",
    "\n",
    "You can also see the curresponding `RagasEvaluatorChain` trace too to figure out why ragas scored the way it did.\n",
    "\n",
    "![](../../_static/langsmith-ragas-chain-trace.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
